# pytorchによるディープラーニング実装の流れ

1. 前処理、後処理、ネットワークモデルの出力を確認
2. Datasetの作成
3. DataLoaderの作成
4. ネットワークモデルの作成
5. 順伝播(forward)の定義
6. 損失関数の定義
7. 最適化手法の設定
8. 学習検証の実施
9. テストデータで推論

## 追記

これからPyTorchで深層学習モデルを構築する場合はPyTorch Lightningを並行して学習して行きましょう。

## DatasetとDataLoaderについて

* **Datasetクラス**
  * 入力するデータとそのラベルなどをペアにして保持したクラス
  * データに対する前処理クラスのインスタンスを与え、対象データのファイルを読み込む際に前処理を自動で適用することができる
* **DataLoaderクラス**
  * Datasetからどのようにデータを取り出すのかを設定するクラス
  * Datasetからミニバッチを取り出しやすい

## ネットワークモデルについて

* **ネットワークモデルの作成**
  * ゼロから全て自分で作成するケース
  * 学習済みモデルをロードして用いるケース
  * 学習済みモデルをベースに自分で改変するケース
* ディープラーニングの応用手法では学習済みモデルをベースに自分で改変するケースが多い

## 順伝播(forward)について

* ディープラーニングの応用手法はネットワークのモデルが途中で分岐したりするため、順伝播が複雑な場合が多い
* 単純なネットークモデルは前から後ろに流れるだけだが、そうはいかないのできちんと順伝播関数(forward)を定義すること

## 損失関数について

* 誤差逆伝播(Backpropagation)をするために定義する
* 単純なディープラーニングの手法であれば２乗誤差など単純な関数だが、ディープラーニングの応用手法ではもっと複雑なものが使われる

## 最適化手法について

* ネットワークモデルの結合パラメータを学習させる際に使うもの
* 誤差逆伝播によって結合パラメータの誤差に対する勾配が求まるので、その勾配を使って、結合パラメータの修正量をどのように計算するのかを設定する
* Momentum SGD、Adamなどがある

## 学習と検証、推論について

* 基本的にはepochごとに訓練データでの性能と検証データでの性能を確認する
* 検証データの性能が向上しなくなったら、その後は訓練データに対してか学習に陥っていくため、そのタイミングで学習を終了させることが多い
  * early stopping
* 学習が終了後にテストデータに対して推論を行う

## 転移学習の実装

1. 画像データからDatasetを作成する
2. DatasetからDataLoaderを作成
3. 学習済みモデルの出力層を任意の形に変更
4. 出力層の結合パラメータのみを学習させ、転移学習を実装

* **転移学習**
  * 学習済みモデルをベースに、最終の出力層を付け替えて学習させる手法
  * 最終出力層を自前のデータに対応した出力層に付け替えて、付け替えた出力層への結合パラメータを手元にある少量のデータで学習し直すということ
  * 学習済みモデルをベースとするので自前のデータが少量でも性能のいいディープラーニングを実現しやすいというメリットが！
* **ファインチューニング**
  * 学習済みモデルをベースに出力層などを変更したモデルを構築し、自前のデータでニューラルネットワーク・モデルの結合パラメータを学習させる手法
  * 結合パラメータの初期値には学習済みのモデルのパラメータを利用する
  * 転移学習とは異なり、出力層・出力層に近い部分だけでなく、全層のパラメータを再学習させる
  * 入力層に近い部分のパラメータは学習率を小さく設定し、出力層に近い部分のパラメータは学習率を大きく設定することが一般的
  * 転移学習と同じで、自前のデータが少量でも性能のいいでディープラーニングを実現しやすいというメリットがある
  * 最適化手法の設定部分が転移学習と異なる

### Datasetを作成

* Datasetを作成する場合、torchvision.datasets.ImageFolderクラスを利用する手法が簡単
* 上のやり方は簡単だが、Datasetは自分でも作れる
* **Data Augmentation**
  * トレーニングデータに対してランダムに異なる画像変換を適用し、データを水増しする手法。以下のようなクラスが用いられる。
  * **randomresizedcrop**：指定されたPILイメージをランダムなサイズとアスペクト比にトリミングするクラス
  * （使用例）**RandomResizedCrop(resize, scale=(0.5~1.0))**
    * 0.5~1.0の大きさで拡大縮小
    * さらにアスペクト比を3/4から4/3の間のいずれかで変更して画像を横もしくは縦に引き伸ばす
    * 最後にresizeで指定した大きさで画像を切り出す
  * **RandomHorizontalFlip**：指定された確率で、指定されたPIL画像を水平方向にランダムに反転するクラス
  * （使用例）**RandomHorizontalFlip()**
    * 画像の左右を50%の確率で反転させる操作
  * [torchvision.transforms](https://pytorch.org/docs/stable/torchvision/transforms.html)
  * albumentationsもええぞ

データの水増しを行い多様なデータを学習することでテストデータに対する性能（汎化性能）が向上しやすくなる！

### DataLoaderを作成

* Datasetを利用して作成する
* [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html)
* **shuffle=True**
  * 画像を取り出す順番がランダムになるようにする

### 損失関数を定義

* 通常のクラス分類はクロスエントロピー誤差関数を使用
* **クロスエントロピー誤差関数**
  * 全結合層からの出力に対してソフトマックス関数を適用したあと、クラス分類の損失関数であるThe negative log likelihood loss(負の対数尤度損失?)を計算する

### 最適化手法を設定

* (深層学習の最適化アルゴリズム)[https://qiita.com/ZoneTsuyoshi/items/8ef6fa1e154d176e25b8]
* requires_grad
  * 自動微分の対象の勾配の計算をするかしないかを設定するもの
* **requires_grad = True**
  * 誤差逆伝播で勾配が計算され、学習時に値が変化する(自動微分を行う)
* **requires_grad = False**
  * パラメータを固定させ、更新したくない時に使う(自動微分を行わない)

### 学習・検証を実施

* Dropoutや勾配計算は訓練時にのみ行い、予測時には使用しないのが通常
  * なので、ネットワークを訓練モード、検証モードにしてわける
  * （例）net.train(), net.eval()
* 検証時には勾配を計算する必要がないので、if文で場合分けを行う

## ファインチューニングの実装

* 最適化の方法が転移学習と異なる
  * 全層のパラメータを学習できるようにoptimizerを設定
