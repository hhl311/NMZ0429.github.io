
<!doctype html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.0.6">
    
    
      
        <title>【もうやりたくない】RNNとLSTMの理解とNumPyによる実装 - Cheep Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2c0c5eaf.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.7fa14f5b.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/notosansjp.css">
    
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:600,800">
    
      <link rel="stylesheet" href="../../css/custom.css">
    
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.1/css/font-awesome.min.css">
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-196492429-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#rnnlstmnumpy" class="md-skip">
          コンテンツにスキップ
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="ヘッダー">
    <a href="../.." title="Cheep Learning" class="md-header__button md-logo" aria-label="Cheep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cheep Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              【もうやりたくない】RNNとLSTMの理解とNumPyによる実装
            
          </span>
        </div>
      </div>
    </div>
    <div class="md-header__options">
      
    </div>
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="検索" placeholder="検索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="クリア" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            検索を初期化
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="タブ" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Welcome !!
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../intro/" class="md-tabs__link">
      Artificial Intelligenceを学ぶ方へ
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../100%E6%9C%AC%E3%83%8E%E3%83%83%E3%82%AF/a_nlp/" class="md-tabs__link">
        100本ノック
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../PyTorch/PyTorch/a_pytorch/" class="md-tabs__link">
        PyTorch
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E3%81%9D%E3%81%AE%E4%BB%96/glossary/" class="md-tabs__link">
        その他
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E3%83%84%E3%83%BC%E3%83%AB/heroku_st/" class="md-tabs__link">
        ツール
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../3dvision/" class="md-tabs__link md-tabs__link--active">
        深層学習
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AB/eval_rec/" class="md-tabs__link">
        統計モデル
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/GNN/" class="md-tabs__link">
        論文解説
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="ナビゲーション" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Cheep Learning" class="md-nav__button md-logo" aria-label="Cheep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Cheep Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Welcome !!
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../intro/" class="md-nav__link">
        Artificial Intelligenceを学ぶ方へ
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        100本ノック
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="100本ノック" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          100本ノック
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../100%E6%9C%AC%E3%83%8E%E3%83%83%E3%82%AF/a_nlp/" class="md-nav__link">
        自然言語処理100本ノックまとめ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../100%E6%9C%AC%E3%83%8E%E3%83%83%E3%82%AF/b_image/" class="md-nav__link">
        画像処理100本ノック答え
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../100%E6%9C%AC%E3%83%8E%E3%83%83%E3%82%AF/c_numpy/" class="md-nav__link">
        Numpy100本ノック答え
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="PyTorch" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" data-md-state="indeterminate" type="checkbox" id="__nav_4_1" checked>
      
      <label class="md-nav__link" for="__nav_4_1">
        PyTorch
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="PyTorch" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch/a_pytorch/" class="md-nav__link">
        pytorchによるディープラーニング実装の流れ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch/dp/" class="md-nav__link">
        PyTorchの分散計算処理を使う
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch/video/" class="md-nav__link">
        PyTorch Dataset API で動画データを扱う方法
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" data-md-state="indeterminate" type="checkbox" id="__nav_4_2" checked>
      
      <label class="md-nav__link" for="__nav_4_2">
        PyTorch Lightning
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="PyTorch Lightning" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          PyTorch Lightning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch%20Lightning/checkpoint/" class="md-nav__link">
        PyTorch LightningのCheckpointCallbackの便利機能
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch%20Lightning/data_module/" class="md-nav__link">
        【PyTorch Lightning】LightningDataModuleについて
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch%20Lightning/lightning_bolts/" class="md-nav__link">
        PyTorch Lightning Boltsの使い方
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/PyTorch%20Lightning/pytorchvideo/" class="md-nav__link">
        PyTorchVideo 使い方
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      <label class="md-nav__link" for="__nav_5">
        その他
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="その他" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          その他
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%81%9D%E3%81%AE%E4%BB%96/glossary/" class="md-nav__link">
        機械学習用語辞典
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%81%9D%E3%81%AE%E4%BB%96/python_study/" class="md-nav__link">
        Pythonのお勉強に使える書籍のまとめ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%81%9D%E3%81%AE%E4%BB%96/%E3%83%AF%E3%83%BC%E3%82%AF%E3%83%95%E3%83%AD%E3%83%BC/" class="md-nav__link">
        ワークフロー
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%81%9D%E3%81%AE%E4%BB%96/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%83%AF%E3%83%BC%E3%82%AF/" class="md-nav__link">
        強化学習フレームワークまとめ
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" data-md-state="indeterminate" type="checkbox" id="__nav_6" checked>
      
      <label class="md-nav__link" for="__nav_6">
        ツール
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="ツール" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          ツール
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%83%84%E3%83%BC%E3%83%AB/heroku_st/" class="md-nav__link">
        StreamlitアプリをHerokuでティプロイする
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%83%84%E3%83%BC%E3%83%AB/plantuml/" class="md-nav__link">
        PlantUMLのススメ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E3%83%84%E3%83%BC%E3%83%AB/tmux/" class="md-nav__link">
        tmuxはええぞ
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" checked>
      
      <label class="md-nav__link" for="__nav_7">
        深層学習
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="深層学習" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          深層学習
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../3dvision/" class="md-nav__link">
        3D vision
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          【もうやりたくない】RNNとLSTMの理解とNumPyによる実装
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        【もうやりたくない】RNNとLSTMの理解とNumPyによる実装
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目次
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    時系列データの表現の仕方
  </a>
  
    <nav class="md-nav" aria-label="時系列データの表現の仕方">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-hot-encoding" class="md-nav__link">
    単語に対するone-hot encoding
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    データセットの生成
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    データセットの分割
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn" class="md-nav__link">
    RNNの導入
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn_1" class="md-nav__link">
    RNNの実装
  </a>
  
    <nav class="md-nav" aria-label="RNNの実装">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_2" class="md-nav__link">
    RNNの初期化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    活性化関数の実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-pass" class="md-nav__link">
    forward passの実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward-pass" class="md-nav__link">
    backward passの実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    学習
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../video_task/" class="md-nav__link">
        動画を使った深層学習
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" data-md-state="indeterminate" type="checkbox" id="__nav_8" checked>
      
      <label class="md-nav__link" for="__nav_8">
        統計モデル
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="統計モデル" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          統計モデル
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AB/eval_rec/" class="md-nav__link">
        推薦システムの評価指標
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AB/method/" class="md-nav__link">
        推薦モデル
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AB/silimarity/" class="md-nav__link">
        サンプル間の類似性指標
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AB/use_case/" class="md-nav__link">
        学習ベース推薦システムの活用事例
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" data-md-state="indeterminate" type="checkbox" id="__nav_9" checked>
      
      <label class="md-nav__link" for="__nav_9">
        論文解説
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="論文解説" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          論文解説
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/GNN/" class="md-nav__link">
        Graph Attention Network 解説
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/SGD%E6%9C%80%E9%81%A9%E5%8C%96%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E3%82%AF%E3%83%AC%E3%83%B3%E3%82%B8%E3%83%B3%E3%82%B0%E6%89%8B%E6%B3%95/" class="md-nav__link">
        SGD最適化モデルに対するデータクレンジング手法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/fast_rcnn/" class="md-nav__link">
        Faster R-CNN まとめ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/feature_learning/" class="md-nav__link">
        表現学習についてまとめのまとめのまとめ
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/mesh_rcnn/" class="md-nav__link">
        Mesh RCNNのお気持ちを理解したい
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/paper_list/" class="md-nav__link">
        読んだ論文まとめ（随時更新）
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/posenet/" class="md-nav__link">
        TensorflowでPosenetによる姿勢推定
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%AC/vision_transformer/" class="md-nav__link">
        Video Vision Transformer
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目次
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    時系列データの表現の仕方
  </a>
  
    <nav class="md-nav" aria-label="時系列データの表現の仕方">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#one-hot-encoding" class="md-nav__link">
    単語に対するone-hot encoding
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    データセットの生成
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    データセットの分割
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn" class="md-nav__link">
    RNNの導入
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rnn_1" class="md-nav__link">
    RNNの実装
  </a>
  
    <nav class="md-nav" aria-label="RNNの実装">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_2" class="md-nav__link">
    RNNの初期化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    活性化関数の実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-pass" class="md-nav__link">
    forward passの実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward-pass" class="md-nav__link">
    backward passの実装
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    学習
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="rnnlstmnumpy">【もうやりたくない】RNNとLSTMの理解とNumPyによる実装</h1>
<p>ニューラルネットワークを用いた系列データを学習する方法について書きます。系列データの学習には、単語予測や天気予測など様々な応用先があります。</p>
<p>この流れで解説していきたいと思います。</p>
<ul>
<li>ニューラルネットワークでは、カテゴリー変数の表現の仕方</li>
<li>RNNの実装の仕方</li>
<li>LSTMの実装の仕方</li>
<li>PyTorchを使ったLSTMの実装の仕方</li>
</ul>
<h2 id="_1">時系列データの表現の仕方</h2>
<p>時系列データをニューラルネットワークに入力するには、何かしらの方法で時系列データをニューラルネットワークに入力できる形に表現する必要があります。ここでは、one-hot encodingを使用していきたいと思います。</p>
<h3 id="one-hot-encoding">単語に対するone-hot encoding</h3>
<p>単語をone-hot vectorに変換します。しかし、単語の量が膨大になるとone-hot vectorの大きさも膨大になるので、工夫を行います。</p>
<p>使用頻度の高いk個の単語を残しそれ以外の単語はUNKとして、one-hot vectorに変換します。</p>
<h2 id="_2">データセットの生成</h2>
<p>a b a EOS,</p>
<p>a a b b a a EOS,</p>
<p>a a a a a b b b b b a a a a a EOS</p>
<p>のようなデータセットを生成することを考えます。</p>
<p>EOSは、end of a sequenceの略です。</p>
<p>```Python:
import numpy as np</p>
<p>np.random.seed(42)#乱数を固定する</p>
<p>def generate_dataset(num_sequences=2**8):
    """
    データセットを生成する関数
    num_sequences 周期
    return 系列データのリスト
    """
    samples = []</p>
<pre><code>for _ in range(num_sequences):
    num_tokens = np.random.randint(1, 6)#1から6までの数を1つ生成
    sample = ['a'] * num_tokens + ['b'] * num_tokens + ['a'] * num_tokens + ['EOS']
    samples.append(sample)

return samples
</code></pre>
<p>sequences = generate_dataset()
<div class="highlight"><pre><span></span><code>## 系列データの単語とその出現頻度を調べる

one-hot encodingをするために、系列データの単語とその出現頻度を格納している辞書を作ります。

defaultdictを使うことで、辞書のvalueの値を任意に初期化できるみたいです。

```Python:
from collections import defaultdict

def sequences_to_dicts(sequences):
    &quot;&quot;&quot;
    単語とその出現頻度を格納する辞書を作る
    &quot;&quot;&quot;
    flatten = lambda l: [item for sublist in l for item in sublist]#listを全部つなげる

    all_words = flatten(sequences)

    word_count = defaultdict(int)#辞書の初期化
    for word in flatten(sequences):
        #頻度を数える
        word_count[word] += 1

    word_count = sorted(list(word_count.items()), key=lambda l: -l[1])#word_countのkeyとvalueをvalueに基づいて降順にソート

    unique_words = [item[0] for item in word_count]#単語をとる

    unique_words.append(&#39;UNK&#39;)#UNKを追加

    num_sequences, vocab_size = len(sequences), len(unique_words)

    word_to_idx = defaultdict(lambda: vocab_size-1)#初期値の設定
    idx_to_word = defaultdict(lambda: &#39;UNK&#39;)


    for idx, word in enumerate(unique_words):
        #enumerateでindexと要素を取得
        #辞書に入れる
        word_to_idx[word] = idx
        idx_to_word[idx] = word

    return word_to_idx, idx_to_word, num_sequences, vocab_size

word_to_idx, idx_to_word, num_sequences, vocab_size = sequences_to_dicts(sequences)
</code></pre></div></p>
<h2 id="_3">データセットの分割</h2>
<p>系列データをtraining, validation, testに分割します。
それぞれ、80%, 10%, 10%です。
系列データsequencesの分割には、スライスを使っています。</p>
<p>スライスを使うと、<code>l[start:goal]</code>でl[start]からl[goal-1]の値を抽出できます。startとgoalは半開区間になっており、l[goal]は含まれません。</p>
<p>startとgoalは省略することができます。</p>
<p><code>l[:goal]</code>はl[0]からl[goal-1]まで、
<code>l[start:]</code>はl[start]からl<a href="最後">l.size()-1</a>まで抽出できます。
<code>l[:]</code>は全部抽出します。</p>
<p><code>l[-n:]</code>は最後から数えてn個の要素を抽出します。</p>
<p><code>l[:-n]</code>はl[0]から抽出しますが、最後のn個は抽出しません。</p>
<p>PyTorchを用いてデータセットを定義します。</p>
<p>```Python:
from torch.utils import data</p>
<p>class Dataset(data.Dataset):
    def <strong>init</strong>(self, inputs, targets):
        self.intputs = inputs
        self.targets = targets</p>
<pre><code>def __len__(self):
    return len(self.targets)

def __getitem__(self, index):
    X = self.inputs[index]
    y = self.targets[index]

    return X, y
</code></pre>
<p>def create_datasets(sequences, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):
    #分割するサイズを定義
    num_train = int(len(sequences)<em>p_train)
    num_val = int(len(sequences)</em>p_val)
    num_test = int(len(sequences)*p_test)</p>
<pre><code>#系列データを分割
#スライスを利用
sequences_train = sequences[:num_train]
sequences_val = sequences[num_train:num_train+num_val]
sequences_test = sequences[-num_test:]

def get_inputs_targets_from_sequences(sequences):
    inputs, targets = [], []

    #長さLのsequenceからEOSを除いたL-1
    # targetsはinputsのground truthのため右に1つずらす
    for sequence in sequences:
        inputs.append(sequence[:-1])
        targets.append(sequence[1:])

    return inputs, targets

#inputとtargetを作る
inputs_train, targets_train = get_inputs_targets_from_sequences(sequences_train)
inputs_val, targets_val = get_inputs_targets_from_sequences(sequences_val)
inputs_test, targets_test = get_inputs_targets_from_sequences(sequences_test)

#先ほど定義したclassを用いてdatasetを作る
training_set = dataset_class(inputs_train, targets_train)
validation_set = dataset_class(inputs_val, targets_val)
test_set = dataset_class(inputs_test, targets_test)

return training_set, validation_set, test_set
</code></pre>
<p>training_set, validation_set, test_set = create_datasets(sequences, Dataset)
<div class="highlight"><pre><span></span><code>## one-hot vector化

系列データに現れる単語を頻度に基づいてone-hot vectorに変換します。

```Python:
def one_hot_encode(idx, vocab_size):
    &quot;&quot;&quot;
    one-hot vector化する。
    &quot;&quot;&quot;
    one_hot = np.zeros(vocab_size)#vocab_size = 4なら[0, 0, 0, 0]
    one_hot[idx] = 1.0#idx = 1なら[0, 1, 0, 0]
    return one_hot

def one_hot_encode_sequence(sequence, vocab_size):
    &quot;&quot;&quot;
    return 3-D numpy array (num_words, vocab_size, 1)
    &quot;&quot;&quot;
    encoding = np.array([one_hot_encode(word_to_idx[word], vocab_size) for word in sequence])

    #reshape
    encoding = encoding.reshape(encoding.shape[0], encoding.shape[1], 1)

    return encoding
</code></pre></div></p>
<h2 id="rnn">RNNの導入</h2>
<p>Recurrent neural network (RNN)は、系列データの分析が得意です。RNNは、前の状態で使った計算結果を現在の状態に利用することができます。ネットワークの概要図は以下の通りです。</p>
<p><img alt="" src="http://namazu.tokyo/wp-content/uploads/2021/03/fa2a16de005afd238a1253353bbbb4fe-300x100.png" /></p>
<ul>
<li>xは入力である系列データ</li>
<li>Uは入力に対する重み行列</li>
<li>Vはメモリーに対する重み行列</li>
<li>Wは出力を計算するための隠れ状態に対する重み行列</li>
<li>hは時間ごとの隠れ状態(メモリー)</li>
<li>oは出力</li>
</ul>
<h2 id="rnn_1">RNNの実装</h2>
<p>NumPyを使って、RNNの実装をforward pass, backward pass, optimization, training loopの順でやります。</p>
<h3 id="rnn_2">RNNの初期化</h3>
<p>ネットワークを初期化する関数を定義します。</p>
<p>```Python:
hidden_size = 50#隠れ層(メモリー)の次元
vocab_size = len(word_to_idx)</p>
<p>def init_orthogonal(param):
    """
    パラメータを直交化して初期化
    """</p>
<pre><code>if param.ndim &lt; 2:
    raise ValueError("Only parameters with 2 or more dimensions are supported.")

rows, cols = param.shape

new_param = np.random.randn(rows, cols)

if rows &lt; cols:
    new_param = new_param.T

q, r = np.linalg.qr(new_param)

d = np.diag(r, 0)
ph = np.sign(d)
q *= ph

if rows &lt; cols:
    q = q.T

new_param = q

return new_param
</code></pre>
<p>def init_rnn(hidden_size, vocab_size):
    """
    RNNを初期化
    """
    U = np.zeros((hidden_size, vocab_size))
    V = np.zeros((hidden_size, hidden_size))
    W = np.zeros((vocab_size, hidden_size))
    b_hidden = np.zeros((hidden_size, 1))
    b_out = np.zeros((vocab_size, 1))</p>
<pre><code>U = init_orthogonal(U)
V = init_orthogonal(V)
W = init_orthogonal(W)

return U, V, W, b_hidden, b_out
</code></pre>
<p>```
</p>
<h3 id="_4">活性化関数の実装</h3>
<p>sigmoid,tanh, softmaxの実装をしました。
オーバーフロー対策に入力xに微少量を足しています。
また、backward pass用に微分も計算しています。

<code>Python:
def sigmoid(x, derivative=False):
    x_safe = x + 1e-12#微少量を足す
    f = 1/(1 + np.exp(-x_safe))

    if derivative:
        return f * (1 -f)#微分を返す
    else:
        return f

def tanh(x, derivative=False):
    x_safe = x + 1e-12
    f = (np.exp(x_safe) - np.exp(-x_safe))/(np.exp(x_safe)+np.exp(-x_safe))

    if derivative:
        return 1-f**2
    else:
        return f

def softmax(x, derivative=False):
    x_safe = x + 1e-12
    f = np.exp(x_safe)/np.sum(np.exp(x_safe))

    if derivative:
        pass
    else:
        return f</code></p>
<h3 id="forward-pass">forward passの実装</h3>
<ul>
<li>h = tanh(Ux + Vh + b_hidden)</li>
<li>o = softmax(Wh + b_out)
  RNNのforward passは上式で表されるので、実装は以下の通りです。</li>
</ul>
<p>```Python:
def forward_pass(inputs, hidden_state, params):
    U, V, W, b_hidden, b_out = params</p>
<pre><code>outputs, hidden_states = [], []

for t in range(len(inputs)):
    hidden_state = tanh(np.dot(U, inputs[t]) + np.dot(V, hidden_state) + b_hidden)

    out = softmax(np.dot(W, hidden_state) + b_out)
    outputs.append(out)
    hidden_states.append(hidden_state.copy())

return outputs, hidden_states
</code></pre>
<p>```
</p>
<h3 id="backward-pass">backward passの実装</h3>
<p>forward passで損失の勾配を計算するのは時間がかかるので、逆誤差伝播法(backpropagation)を用いて勾配を計算するbackward passを実装します。

勾配爆発対策用の勾配をクリップする関数を作ります。
勾配の大きさが上限値を超えたら、上限値で正規化します。

<code>Python:
def clip_gradient_norm(grads, max_norm=0.25):
    """
    勾配爆発対策で
    勾配を
    g = (max_nrom/|g|)*gに変換する
    """
    max_norm = float(max_norm)
    total_norm = 0

    for grad in grads:
        grad_norm = np.sum(np.power(grad, 2))
        total_norm += grad_norm

    total_norm = np.sqrt(total_norm)

    clip_coef = max_norm / (total_norm + 1e-6)

    if clip_coef &lt; 1:
        for grad in grads:
            grad *= clip_coef

    return grads</code></p>
<p>backward_passを計算する関数を作ります。損失を求めて、逆誤差伝播法でそれぞれのパラメータで微分した損失の勾配を求めます。</p>
<p>```Python:
def backward_pass(inputs, outputs, hidden_states, targets, params):
    U, V, W, b_hidden, b_out = params</p>
<pre><code>d_U, d_V, d_W = np.zeros_like(U), np.zeros_like(V), np.zeros_like(W)
d_b_hidden, d_b_out = np.zeros_like(b_hidden), np.zeros_like(b_out)

d_h_next = np.zeros_like(hidden_states[0])
loss = 0

for t in reversed(range(len(outputs))):
    #cross entropy lossを計算
    loss += -np.mean(np.log(outputs[t]+1e-12)*targets[t])

    #backpropagate into output
    d_o = outputs[t].copy()
    d_o[np.argmax(targets[t])] -= -1

    #backpropagate into W
    d_W += np.dot(d_o, hidden_states[t].T)
    d_b_out += d_o

    #backpropagate into h
    d_h = np.dot(W.T, d_o) + d_h_next

    #backpropagate through non-linearity
    d_f = tanh(hidden_states[t], derivative=True) * d_h
    d_b_hidden += d_f

    #backpropagate into U
    d_U += np.dot(d_f, inputs[t].T)

    #backpropagate into V
    d_V += np.dot(d_f, hidden_states[t-1].T)
    d_h_next = np.dot(V.T, d_f)

grads = d_U, d_V, d_W, d_b_hidden, d_b_out

grads = clip_gradient_norm(grads)

return loss, grads
</code></pre>
<div class="highlight"><pre><span></span><code>### optimization

勾配降下法を用いて、RNNのパラメータを更新します。今回は確率的勾配降下法(SGD)を使用します。

```Python:
def update_paramaters(params, grads, lr=1e-3):
    for param, gras in zip(params, grads):
        #zipで複数のリストの要素を取得
        param -= lr * grad

    return params
</code></pre></div>
<h3 id="_5">学習</h3>
<p>実装したRNNの学習を行います。LossのグラフはTensorBoardを使用して描画しました。</p>
<p>```Python:
from torch.utils.tensorboard import SummaryWriter</p>
<p>writer = SummaryWriter(log_dir="./logs")#SummaryWriter のインスタンスを生成 保存するディレクトリも指定</p>
<p>num_epochs = 1000</p>
<h1 id="_6">パラメータの初期化</h1>
<p>params = init_rnn(hidden_size=hidden_size, vocab_size=vocab_size)</p>
<p>hidden_state = np.zeros((hidden_size, 1))</p>
<p>for i in range(num_epochs):</p>
<pre><code>epoch_training_loss = 0
epoch_validation_loss = 0

#validationのループ sentenceごとにループを回す
for inputs, targets in validation_set:
    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

    #初期化
    hidde_state = np.zeros_like(hidden_state)

    #forward pass
    outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)

    #backward pass 今はvalidationなのでLossのみを計算
    loss, _ = backward_pass(inputs_one_hot, outputs, hidden_states, targets_one_hot, params)

    epoch_validation_loss += loss

#trainingのループ sentenceごとにループを回す
for inputs, targets in training_set:
    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

    #初期化
    hidde_state = np.zeros_like(hidden_state)

    #forward pass
    outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)

    #backward pass trainingなので勾配も計算
    loss, grads = backward_pass(inputs_one_hot, outputs, hidden_states, targets_one_hot, params)

    if np.isnan(loss):
        raise ValueError('Gradients have vanished')

    #networkのパラメータを更新
    params = update_paramaters(params, grads)

    epoch_training_loss += loss

writer.add_scalars("Loss", {"val":epoch_validation_loss/len(validation_set), "train":epoch_training_loss/len(training_set)}, i)
</code></pre>
<p>writer.close()
<div class="highlight"><pre><span></span><code>![](http://namazu.tokyo/wp-content/uploads/2021/03/dd8661aaa3a8f79f8c27c79cff2db71f-300x200.png)

Lossのグラフです。綺麗にプロットできています。赤がtrain, 青がvalを表しています。
あまり上手く学習できていないことがわかります。隠れ層の次元が少ないことやループが少ないことやパラメータの初期値が合ってないことが原因でしょうか?

### テスト

学習したRNNのテストをします。適当に文章を生成し、それに対して次のwordを予測します。

Pythonでは、`list[-1]`で一番後ろの値を取得することができるみたいです。

```Python:
def freestyle(params, sentence=&#39;&#39;, num_generate=10):
    sentence = sentence.split(&#39; &#39;)#空白で区切る
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)

    hidden_state = np.zeros((hidden_size, 1))

    outputs, hidden_states = forward_pass(sentence_one_hot, hidde_state, params)

    output_sentence = sentence

    word = idx_to_word[np.argmax(outputs[-1])]
    output_sentence.append(word)

    for i in range(num_generate):

        output = outputs[-1]#一番後ろの値を取得
        hidden_state = hidden_states[-1]

        output = output.reshape(1, output.shape[0], output.shape[1])

        outputs, hidden_states = forward_pass(output, hidde_state, params)

        word = idx_to_word[np.argmax(outputs)]

        output_sentence.append(word)

        if word == &quot;EOS&quot;:
            break

    return output_sentence


test_examples = [&#39;a a b&#39;, &#39;a a a a b&#39;, &#39;a a a a a a b&#39;, &#39;a&#39;, &#39;r n n&#39;]
for i, test_example in enumerate(test_examples):
    print(f&#39;Example {i}:&#39;, test_example)
    print(&#39;Predicted sequence:&#39;, freestyle(params, sentence=test_example), end=&#39;\n\n&#39;)
</code></pre></div></p>
<p>上手く学習していないので、テストも上手くいってないことが結果からわかります。
全てUnknownと予測しています。</p>
<p>```Shell:テスト結果
Example 0: a a b
Predicted sequence: ['a', 'a', 'b', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']</p>
<p>Example 1: a a a a b
Predicted sequence: ['a', 'a', 'a', 'a', 'b', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']</p>
<p>Example 2: a a a a a a b
Predicted sequence: ['a', 'a', 'a', 'a', 'a', 'a', 'b', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']</p>
<p>Example 3: a
Predicted sequence: ['a', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']</p>
<p>Example 4: r n n
Predicted sequence: ['r', 'n', 'n', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']
<div class="highlight"><pre><span></span><code>## LSTMの導入

RNNは、ギャップが大きくなるにつれて情報を関連づけて学習するのが難しくなります。
このような長期依存性を学習できるようにしたのが、Long Short Term Memory(LSTM)です。LSTMは、RNNの派生で同じように繰り返しモジュールになっています。

![](http://namazu.tokyo/wp-content/uploads/2021/03/93056c52056f15d863e0d4fb0cc89948-300x113.png)

### LSTMの仕組み

LSTMは、忘却ゲート層、入力ゲート層、出力ゲート層の3つで構成されています。
LSTMはセルと呼ばれるメモリーが情報を保持しています。Cがセル、xが入力、hが出力、Wが重み、bがバイアスです。

まず、忘却ゲート層で、セル状態から捨てる情報を判定します。現在の入力と、1ステップ前の出力をシグモイド関数にいれます。0から1の間の数値が出力されます。0が完全に捨てるを表し、1が完全に維持を表します。

![](http://namazu.tokyo/wp-content/uploads/2021/03/7188d6629f92af532044727371464615-300x93.png)

次に、入力ゲート層で、入力に対してどの値を更新するかを判定します。tanh層でセル状態に加えられる新たな候補値のベクトルを作成します。

![](http://namazu.tokyo/wp-content/uploads/2021/03/eaed8d1ee52ddcefbf9ef8b3aadb5fc8-300x93.png)

セルを更新します。1ステップ前の忘却済みのセルと更新する値を足し合わせます。

![](http://namazu.tokyo/wp-content/uploads/2021/03/196a34321e796c678b1fc2d400977997-300x93.png)

最後に、出力ゲート層で、セル状態に基づいて出力するものを判定します。

![](http://namazu.tokyo/wp-content/uploads/2021/03/dea185317c8a1cbc486670eb6aae4ef5-300x93.png)

## LSTMの実装

NumPyを使って、LSTMの実装をforward pass, backward pass, optimization, training loopの順でやります。

### LSTMの初期化

ネットワークを初期化する関数を定義します。

```Python:
z_size = hidden_size + vocab_size

def init_lstm(hidden_size, vocab_size, z_size):
    &quot;&quot;&quot;
    LSTMの初期化
    &quot;&quot;&quot;

    W_f = np.random.randn(hidden_size, z_size)

    b_f = np.zeros((hidden_size, 1))

    W_i = np.random.randn(hidden_size, z_size)

    b_i = np.zeros((hidden_size, 1))

    W_g = np.random.randn(hidden_size, z_size)

    b_g = np.zeros((hidden_size, 1))

    W_o = np.random.randn(hidden_size, z_size)
    b_o = np.zeros((hidden_size, 1))

    W_v = np.random.randn(vocab_size, hidden_size)
    b_v = np.zeros((vocab_size, 1))

    W_f = init_orthogonal(W_f)
    W_i = init_orthogonal(W_i)
    W_g = init_orthogonal(W_g)
    W_o = init_orthogonal(W_o)
    W_v = init_orthogonal(W_v)

    return W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v
</code></pre></div></p>
<h3 id="forward-pass_1">forward passの実装</h3>
<p>LSTMの仕組みにあるデータの流れ通りに実装します。</p>
<p>```Python:
def forward(inputs, h_prev, C_prev, p):
    """
    inputs:現在の入力
    h_prev:1ステップ前の出力
    C_prev:1ステップ前のセル
    p:LSTMのパラメータ
    return 各モジュールの状態と出力
    """
    assert h_prev.shape == (hidden_size, 1)
    assert C_prev.shape == (hidden_size, 1)</p>
<pre><code>W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p

x_s, z_s, f_s, i_s = [], [], [], []
g_s, C_s, o_s, h_s = [], [], [], []
v_s, output_s = [], []

h_s.append(h_prev)
C_s.append(C_prev)


for x in inputs:
    #入力と1ステップ前の出力を結合
    z = np.row_stack((h_prev, x))
    z_s.append(z)

    #忘却ゲート
    f = sigmoid(np.dot(W_f, z) + b_f)
    f_s.append(f)

    #入力ゲート
    i = sigmoid(np.dot(W_i, z) + b_i)
    i_s.append(i)

    #現在の入力に対してセルに加える候補
    g = tanh(np.dot(W_g, z) + b_g)
    g_s.append(g)

    #セルの更新
    C_prev = f * C_prev + i * g
    C_s.append(C_prev)

    #出力ゲート
    o = sigmoid(np.dot(W_o, z) + b_o)
    o_s.append(o)

    #出力する
    h_prev = o * tanh(C_prev)
    h_s.append(h_prev)

    v = np.dot(W_v, h_prev) + b_v
    v_s.append(v)

    output = softmax(v)
    output_s.append(output)

return z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s
</code></pre>
<p>```
</p>
<h3 id="backward-pass_1">backward passの実装</h3>
<p>損失を求めて、逆誤差伝播法でそれぞれのパラメータで微分した損失の勾配を求めます。

<code>Python:
def backward(z, f, i, g, C, o, h, v, outputs, targets, p = params):
    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p

    #勾配を初期化
    W_f_d = np.zeros_like(W_f)
    b_f_d = np.zeros_like(b_f)

    W_i_d = np.zeros_like(W_i)
    b_i_d = np.zeros_like(b_i)

    W_g_d = np.zeros_like(W_g)
    b_g_d = np.zeros_like(b_g)

    W_o_d = np.zeros_like(W_o)
    b_o_d = np.zeros_like(b_o)

    W_v_d = np.zeros_like(W_v)
    b_v_d = np.zeros_like(b_v)

    #次のセルと隠れ状態を初期化
    dh_next = np.zeros_like(h[0])
    dC_next = np.zeros_like(C[0])

    loss = 0

    for t in reversed(range(len(outputs))):
        #クロスエントロピーロスを計算
        loss += -np.mean(np.log(outputs[t]) * targets[t])
        #前のセルを更新
        C_prev = C[t-1]

        dv = np.copy(outputs[t])
        dv[np.argmax(targets[t])] -= 1

        W_v_d += np.dot(dv, h[t].T)
        b_v_d += dv

        dh = np.dot(W_v.T, dv)
        dh += dh_next
        do = dh * tanh(C[t])
        do = sigmoid(o[t], derivative=True)*do

        W_o_d += np.dot(do, z[t].T)
        b_o_d += do

        dC = np.copy(dC_next)
        dC += dh * o[t] * tanh(tanh(C[t]), derivative=True)
        dg = dC * i[t]
        dg = tanh(g[t], derivative=True) * dg

        W_g_d += np.dot(dg, z[t].T)
        b_g_d += dg

        di = dC * g[t]
        di = sigmoid(i[t], True) * di

        W_i_d += np.dot(di, z[t].T)
        b_i_d += di

        df = dC * C_prev
        df = sigmoid(f[t]) * df

        W_f_d += np.dot(df, z[t].T)
        b_f_d += df

        dz = (np.dot(W_f.T, df) + np.dot(W_i.T, di) + np.dot(W_g.T, dg) + np.dot(W_o.T, do))
        dh_prev = dz[:hidden_size, :]
        dC_prev = f[t] * dC

    grads = W_f_d, W_i_d, W_g_d, W_o_d, W_v_d, b_f_d, b_i_d, b_g_d, b_o_d, b_v_d

    grads = clip_gradient_norm(grads)

    return loss, grads</code></p>
<h3 id="_7">学習</h3>
<p>実装したLSTMの学習を行います。LossのグラフはTensorBoardを使用して描画しました。</p>
<p>```Python:
writer = SummaryWriter(log_dir="./logs/lstm")#SummaryWriter のインスタンスを生成 保存するディレクトリも指定</p>
<p>num_epochs = 200#エポック数</p>
<h1 id="lstm">LSTMの初期化</h1>
<p>z_size = hidden_size + vocab_size
params = init_lstm(hidden_size, vocab_size, z_size)</p>
<h1 id="_8">隠れ層の初期化</h1>
<p>hidden_state = np.zeros((hidden_size, 1))</p>
<p>for i in range(num_epochs):</p>
<pre><code>epoch_training_loss = 0
epoch_validation_loss = 0

#validationのループ sentenceごとにループを回す
for inputs, targets in validation_set:
    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

    #初期化
    h = np.zeros((hidden_size, 1))
    c = np.zeros((hidden_size, 1))

    #forward pass
    z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs_one_hot, h, c, params)

    #backward pass 今はvalidationなのでLossのみを計算
    loss, _ = backward(z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs, targets_one_hot, params)

    epoch_validation_loss += loss

#trainのループ sentenceごとにループを回す
for inputs, targets in training_set:
    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

    #初期化
    h = np.zeros((hidden_size, 1))
    c = np.zeros((hidden_size, 1))

    #forward pass
    z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs_one_hot, h, c, params)

    #backward pass 今はtrainingなのでLossと勾配を計算
    loss, grads = backward(z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs, targets_one_hot, params)

    #LSTMの更新
    params = update_paramaters(params, grads, lr=1e-1)
    epoch_training_loss += loss

writer.add_scalars("LSTM Loss", {"val":epoch_validation_loss/len(validation_set), "train":epoch_training_loss/len(training_set)}, i)
</code></pre>
<p>writer.close()
<div class="highlight"><pre><span></span><code>![](http://namazu.tokyo/wp-content/uploads/2021/03/38636fedc882953549a18b2520823905-300x202.png)

Lossのグラフです。綺麗にプロットできています。赤がtrain, 青がvalを表しています。 RNNと比較すると、学習が進むにつれてLossがしっかりと下がっているので安定しています。

## PyTorchを用いたLSTMの実装

フレームワークを使ってLSTMの実装を行います。

### LSTMの定義

まず、LSTMのネットワークを定義します。

```Python:
import torch
import torch.nn as nn
import torch.nn.functional as F

class MyLSTM(nn.Module):
    def __init__(self):
        super(MyLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size=vocab_size, hidden_size=50, num_layers=1, bidirectional=False)
        self.l_out = nn.Linear(in_features=50, out_features=vocab_size, bias=False)

    def forward(self, x):
        x, (h, c) = self.lstm(x)

        x = x.view(-1, self.lstm.hidden_size)

        x = self.l_out(x)

        return x
</code></pre></div></p>
<h3 id="_9">学習</h3>
<p>学習するためのループを書きます。
ロス関数はクロスエントロピー誤差を、optimizerはSGDを用いました。
numpyを用いたときと同様です。</p>
<p>PyTorchでは、クロスエントロピー誤差を用いるとき、targetはone-hot vectorにするのではなく1である箇所(正解の箇所)のインデックスを渡すだけでよいです。</p>
<p>LossのグラフはTensorBoardを使用して描画しました。</p>
<p>```Python:
num_epochs = 200#エポック数</p>
<p>net = MyLSTM()#LSTMのインスタンス生成
net = net.double()#型をfloatからdoubleに変換</p>
<p>criterion = nn.CrossEntropyLoss()#クロスエントロピー誤差を使用
optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)#optimizerを設定
writer = SummaryWriter(log_dir="./logs/lstm_pytorch")#SummaryWriter のインスタンスを生成 保存するディレクトリも指定</p>
<p>for i in range(num_epochs):</p>
<pre><code>epoch_training_loss = 0
epoch_validation_loss = 0

net.eval()#テストモード
#validationのループ sentenceごとにループを回す
for inputs, targets in validation_set:
    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_idx = [word_to_idx[word] for word in targets]

    inputs_one_hot = torch.from_numpy(inputs_one_hot)
    inputs_one_hot = inputs_one_hot.permute(0, 2, 1)

    targets_idx = torch.LongTensor(targets_idx)

    #forward pass 今はvalidationなのでLossのみを計算
    outputs = net(inputs_one_hot)

    loss = criterion(outputs, targets_idx)

    epoch_validation_loss += loss.item()

net.train()#訓練モード
#trainのループ sentenceごとにループを回す
for inputs, targets in training_set:
    optimizer.zero_grad()#勾配の初期化

    #one-hot vector化
    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
    targets_idx = [word_to_idx[word] for word in targets]

    inputs_one_hot = torch.from_numpy(inputs_one_hot)
    inputs_one_hot = inputs_one_hot.permute(0, 2, 1)

    targets_idx = torch.LongTensor(targets_idx)

    #forward pass
    outputs = net(inputs_one_hot)

    #lossの計算
    loss = criterion(outputs, targets_idx)

    #backward pass 今はtrainingなので勾配を計算
    loss.backward()

    #LSTMのパラメータを更新
    optimizer.step()

    epoch_training_loss += loss.item()

writer.add_scalars("LSTM PyTorch Loss", {"val":epoch_validation_loss/len(validation_set), "train":epoch_training_loss/len(training_set)}, i)
</code></pre>
<p>writer.close()
```</p>
<p><img alt="" src="http://namazu.tokyo/wp-content/uploads/2021/03/b0b16c7901b43e9d539d0592458ea55d-300x202.png" /></p>
<p>Lossのグラフです。綺麗にプロットできています。赤がtrain, 青がvalを表しています。
先ほどのnumpyで実装したLSTMより、ロスがしっかりと下がっています。フレームワークを使った方がよいですね。</p>
<h2 id="_10">まとめ</h2>
<p>今回はRNNとLSTMを理解するために、numpyの実装をして軽い実験を行いました。また、PyTorchを用いてLSTMの実装を行いました。</p>
<h2 id="_11">参考文献</h2>
<p><a href="">https://masamunetogetoge.com/gradient-vanish</a>
<a href="">https://qiita.com/naoaki0802/items/7a11cded96f3a6165d01</a>
<a href="">http://kento1109.hatenablog.com/entry/2019/07/06/182247</a>
<a href="">https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca</a>
<a href="https://qiita.com/t_Signull/items/21b82be280b46f467d1b">https://qiita.com/t_Signull/items/21b82be280b46f467d1b</a>
<a href="https://qiita.com/tanuk1647/items/276d2be36f5abb8ea52e">https://qiita.com/tanuk1647/items/276d2be36f5abb8ea52e</a></p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tracking", "navigation.expand"], "translations": {"clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\s\\-\u3000\u3001\u3002\uff0c\uff0e]+", "search.placeholder": "\u691c\u7d22", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044"}, "search": "../../assets/javascripts/workers/search.fb4a9340.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.a1c7c35e.min.js"></script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>